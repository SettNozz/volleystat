#!/usr/bin/env python3
"""
Few-Shot Ball Segmentation Training with MLflow Tracking
Trains U-Net model for few-shot segmentation with proper train/val/test splits.
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
import numpy as np
from PIL import Image
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
import mlflow
import mlflow.pytorch
from datetime import datetime


class UNet(nn.Module):
    def __init__(self, in_channels=6, out_channels=1):
        super(UNet, self).__init__()

        def conv_block(in_ch, out_ch):
            return nn.Sequential(
                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),
                nn.BatchNorm2d(out_ch),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),
                nn.BatchNorm2d(out_ch),
                nn.ReLU(inplace=True)
            )

        self.encoder1 = conv_block(in_channels, 64)
        self.encoder2 = conv_block(64, 128)
        self.bottleneck = conv_block(128, 256)

        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.decoder1 = conv_block(256, 128)

        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.decoder2 = conv_block(128, 64)

        self.final = nn.Conv2d(64, out_channels, kernel_size=1)

    def forward(self, x):
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(F.max_pool2d(enc1, 2))
        bottleneck = self.bottleneck(F.max_pool2d(enc2, 2))

        up1 = self.up1(bottleneck)
        dec1 = self.decoder1(torch.cat([up1, enc2], dim=1))

        up2 = self.up2(dec1)
        dec2 = self.decoder2(torch.cat([up2, enc1], dim=1))

        return torch.sigmoid(self.final(dec2))


class FewShotDatasetV2(torch.utils.data.Dataset):
    """Dataset for few-shot segmentation with proper train/val/test structure."""
    
    def __init__(self, split_dir, transform=None, target_size=(256, 256)):
        self.split_dir = split_dir
        self.transform = transform
        self.target_size = target_size
        
        # Get list of query images
        query_dir = os.path.join(split_dir, 'query')
        self.query_images = [f for f in os.listdir(query_dir) if f.endswith('.jpg')]
        
        # Get list of support images
        support_dir = os.path.join(split_dir, 'support')
        self.support_images = [f for f in os.listdir(support_dir) if f.endswith('.jpg')]
        
    def __len__(self):
        return len(self.query_images)
    
    def __getitem__(self, idx):
        query_name = self.query_images[idx]
        query_path = os.path.join(self.split_dir, 'query', query_name)
        
        # Get corresponding mask and support
        base_name = query_name.replace('.jpg', '')
        mask_name = f"{base_name}_mask.png"
        support_name = f"{base_name}_support.jpg"
        
        mask_path = os.path.join(self.split_dir, 'masks', mask_name)
        support_path = os.path.join(self.split_dir, 'support', support_name)
        
        # Load images
        query_image = Image.open(query_path).convert('RGB')
        support_image = Image.open(support_path).convert('RGB')
        
        # Load mask
        if os.path.exists(mask_path):
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            if mask is None:
                mask = np.zeros(self.target_size, dtype=np.uint8)
        else:
            mask = np.zeros(self.target_size, dtype=np.uint8)
        
        # Apply transforms
        if self.transform:
            query_image = self.transform(query_image)
            support_image = self.transform(support_image)
        
        # Concatenate query and support images (6 channels)
        input_tensor = torch.cat([query_image, support_image], dim=0)
        
        # Convert mask to tensor and resize
        mask = cv2.resize(mask, self.target_size)
        mask = torch.from_numpy(mask).float() / 255.0
        
        return input_tensor, mask


def train_model_with_mlflow_v2(
    model, 
    train_loader, 
    val_loader, 
    test_loader,
    num_epochs=100, 
    learning_rate=1e-3, 
    device='cuda',
    experiment_name="few_shot_ball_segmentation_v2"
):
    """Train the few-shot segmentation model with MLflow tracking."""
    
    # Set up MLflow
    mlflow.set_experiment(experiment_name)
    
    with mlflow.start_run():
        # Log parameters
        mlflow.log_params({
            "num_epochs": num_epochs,
            "learning_rate": learning_rate,
            "batch_size": train_loader.batch_size,
            "model_type": "Siamese U-Net",
            "input_channels": 6,
            "device": device
        })
        
        model = model.to(device)
        criterion = nn.BCELoss()  # Use BCELoss since model outputs sigmoid
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)
        
        # Training history
        train_losses = []
        val_losses = []
        best_val_loss = float('inf')
        
        print(f"üöÄ Starting few-shot training for {num_epochs} epochs...")
        print(f"üìä Training samples: {len(train_loader.dataset)}")
        print(f"üìä Validation samples: {len(val_loader.dataset)}")
        print(f"üìä Test samples: {len(test_loader.dataset)}")
        print(f"üî¨ MLflow experiment: {experiment_name}")
        
        for epoch in range(num_epochs):
            # Training phase
            model.train()
            train_loss = 0.0
            
            train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Train]")
            for images, masks in train_pbar:
                images = images.to(device)
                masks = masks.to(device)
                
                # Forward pass
                outputs = model(images)
                loss = criterion(outputs, masks.unsqueeze(1))
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
                train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})
            
            train_loss /= len(train_loader)
            train_losses.append(train_loss)
            
            # Validation phase
            model.eval()
            val_loss = 0.0
            
            with torch.no_grad():
                val_pbar = tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} [Val]")
                for images, masks in val_pbar:
                    images = images.to(device)
                    masks = masks.to(device)
                    
                    outputs = model(images)
                    loss = criterion(outputs, masks.unsqueeze(1))
                    val_loss += loss.item()
                    
                    val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})
            
            val_loss /= len(val_loader)
            val_losses.append(val_loss)
            
            # Learning rate scheduling
            scheduler.step(val_loss)
            
            # Log metrics to MLflow
            mlflow.log_metrics({
                "train_loss": train_loss,
                "val_loss": val_loss,
                "learning_rate": optimizer.param_groups[0]['lr']
            }, step=epoch)
            
            # Save best model
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                mlflow.pytorch.log_model(model, "best_model")
                print(f"üíæ Saved best model (val_loss: {val_loss:.4f})")
            
            print(f"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
            
            # Save checkpoint every 10 epochs
            if (epoch + 1) % 10 == 0:
                checkpoint_path = f'checkpoints/few_shot_v2_checkpoint_epoch_{epoch+1}.pt'
                os.makedirs('checkpoints', exist_ok=True)
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'train_loss': train_loss,
                    'val_loss': val_loss,
                }, checkpoint_path)
                mlflow.log_artifact(checkpoint_path)
        
        # Test phase
        model.eval()
        test_loss = 0.0
        
        with torch.no_grad():
            test_pbar = tqdm(test_loader, desc=f"Final Test")
            for images, masks in test_pbar:
                images = images.to(device)
                masks = masks.to(device)
                
                outputs = model(images)
                loss = criterion(outputs, masks.unsqueeze(1))
                test_loss += loss.item()
                
                test_pbar.set_postfix({'loss': f'{loss.item():.4f}'})
        
        test_loss /= len(test_loader)
        mlflow.log_metrics({"test_loss": test_loss})
        
        # Log final model
        mlflow.pytorch.log_model(model, "final_model")
        
        # Create and log training plots
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 2, 1)
        plt.plot(train_losses, label='Train Loss')
        plt.plot(val_losses, label='Val Loss')
        plt.title('Few-Shot Training History')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True)
        
        plt.subplot(1, 2, 2)
        plt.plot(train_losses, label='Train Loss', alpha=0.7)
        plt.plot(val_losses, label='Val Loss', alpha=0.7)
        plt.title('Few-Shot Training History (Log Scale)')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.yscale('log')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        plot_path = 'few_shot_v2_training_history.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        mlflow.log_artifact(plot_path)
        plt.close()
        
        return train_losses, val_losses, test_loss


def main():
    """Main training function with MLflow tracking."""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python train_few_shot_v2.py <dataset_dir> [num_epochs]")
        print("\nExample:")
        print("  python train_few_shot_v2.py few_shot_datasets_v2/few_shot_run_20241201_120000")
        print("  python train_few_shot_v2.py few_shot_datasets_v2/few_shot_run_20241201_120000 100")
        return
    
    # Configuration
    dataset_dir = sys.argv[1]
    num_epochs = int(sys.argv[2]) if len(sys.argv) > 2 else 100
    
    # Check if dataset exists
    if not os.path.exists(dataset_dir):
        print(f"‚ùå Dataset not found: {dataset_dir}")
        print("üí° First run the dataset preparation script:")
        print("   python prepare_few_shot_dataset_v2.py")
        return
    
    # Data transforms
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # Create datasets
    print("üìä Creating datasets...")
    train_dataset = FewShotDatasetV2(
        os.path.join(dataset_dir, "train"),
        transform=transform
    )
    
    val_dataset = FewShotDatasetV2(
        os.path.join(dataset_dir, "val"),
        transform=transform
    )
    
    test_dataset = FewShotDatasetV2(
        os.path.join(dataset_dir, "test"),
        transform=transform
    )
    
    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)
    
    # Initialize model
    print("üèóÔ∏è Initializing Siamese U-Net model for few-shot segmentation...")
    model = UNet(in_channels=6, out_channels=1)  # 6 channels for Siamese (3 query + 3 support)
    
    # Train model with MLflow tracking
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"üñ•Ô∏è Using device: {device}")
    
    # Create experiment name based on dataset
    dataset_name = os.path.basename(dataset_dir)
    experiment_name = f"few_shot_ball_segmentation_v2_{dataset_name}"
    
    train_losses, val_losses, test_loss = train_model_with_mlflow_v2(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        test_loader=test_loader,
        num_epochs=num_epochs,
        learning_rate=1e-3,
        device=device,
        experiment_name=experiment_name
    )
    
    print(f"\nüéâ Few-shot training completed!")
    print(f"üî¨ MLflow experiment: {experiment_name}")
    print(f"üìä Final test loss: {test_loss:.4f}")
    print(f"üíæ Models logged to MLflow")
    print(f"üìà Training history logged to MLflow")


if __name__ == "__main__":
    main() 